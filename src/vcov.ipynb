{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  get_data import *\n",
    "from  placebo_simulations import *\n",
    "# import  solver\n",
    "from solver import *\n",
    "from  synthdid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_CaliforniaSmoking()\n",
    "PRE_TEREM = [1970, 1988]\n",
    "POST_TEREM = [1989, 2000]\n",
    "\n",
    "TREATMENT = [\"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse_loss(W, X, y, intersept=True) -> float:\n",
    "#     if type(y) == pd.core.frame.DataFrame:\n",
    "#         y = y.mean(axis=1)\n",
    "#     _X = X.copy()\n",
    "#     if intersept:\n",
    "#         _X[\"intersept\"] = 1\n",
    "#     return np.mean(np.sqrt((y - _X.dot(W)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse_loss_with_V(W, V, X, y) -> float:\n",
    "#     if type(y) == pd.core.frame.DataFrame:\n",
    "#         y = y.mean(axis=1)\n",
    "#     _rss = (y - X.dot(W)) ** 2\n",
    "\n",
    "#     _n = len(y)\n",
    "#     _importance = np.zeros((_n, _n))\n",
    "\n",
    "#     np.fill_diagonal(_importance, V)\n",
    "\n",
    "#     return np.sum(_importance @ _rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _v_loss(V, X, y, Y_pre_t, Y_pre_c, return_loss=True):\n",
    "#     Y_pre_t = Y_pre_t.copy()\n",
    "\n",
    "#     n_features = Y_pre_c.shape[1]\n",
    "#     _w = np.repeat(1 / n_features, n_features)\n",
    "\n",
    "#     if type(Y_pre_t) == pd.core.frame.DataFrame:\n",
    "#         Y_pre_t = Y_pre_t.mean(axis=1)\n",
    "\n",
    "#     w_bnds = tuple((0, 1) for i in range(n_features))\n",
    "#     _caled_w = fmin_slsqp(\n",
    "#         partial(rmse_loss_with_V, V=V, X=X, y=y),\n",
    "#         _w,\n",
    "#         f_eqcons=lambda x: np.sum(x) - 1,\n",
    "#         bounds=w_bnds,\n",
    "#         disp=False,\n",
    "#     )\n",
    "#     if return_loss:\n",
    "#         return rmse_loss(_caled_w, Y_pre_c, Y_pre_t, intersept=False)\n",
    "#     else:\n",
    "#         return _caled_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_v(additional_X, additional_y, Y_pre_t, Y_pre_c):\n",
    "#     _len = len(additional_X)\n",
    "#     _v = np.repeat(1 / _len, _len)\n",
    "\n",
    "#     caled_v = fmin_slsqp(\n",
    "#         partial(_v_loss, X=additional_X, y=additional_y, Y_pre_t = Y_pre_t, Y_pre_c = Y_pre_c),\n",
    "#         _v,\n",
    "#         f_eqcons=lambda x: np.sum(x) - 1,\n",
    "#         bounds=tuple((0, 1) for i in range(_len)),\n",
    "#         disp=False,\n",
    "#     )\n",
    "#     return caled_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_omega_ADH(\n",
    "        Y_pre_c, Y_pre_t, additional_X=pd.DataFrame(), additional_y=pd.DataFrame()\n",
    "    ):\n",
    "        \"\"\"\n",
    "        # SC\n",
    "        estimating omega for synthetic control method (not for synthetic diff.-in-diff.)\n",
    "        \"\"\"\n",
    "        Y_pre_t = Y_pre_t.copy()\n",
    "\n",
    "        n_features = Y_pre_c.shape[1]\n",
    "        nrow = Y_pre_c.shape[0]\n",
    "\n",
    "        _w = np.repeat(1 / n_features, n_features)\n",
    "\n",
    "        if type(Y_pre_t) == pd.core.frame.DataFrame:\n",
    "            Y_pre_t = Y_pre_t.mean(axis=1)\n",
    "\n",
    "        # Required to have non negative values\n",
    "        w_bnds = tuple((0, 1) for i in range(n_features))\n",
    "\n",
    "        if len(additional_X) == 0:\n",
    "            caled_w = fmin_slsqp(\n",
    "                partial(rmse_loss, X=Y_pre_c, y=Y_pre_t, intersept=False),\n",
    "                _w,\n",
    "                f_eqcons=lambda x: np.sum(x) - 1,\n",
    "                bounds=w_bnds,\n",
    "                disp=False,\n",
    "            )\n",
    "\n",
    "            return caled_w\n",
    "        else:\n",
    "            assert additional_X.shape[1] == Y_pre_c.shape[1]\n",
    "            if type(additional_y) == pd.core.frame.DataFrame:\n",
    "                additional_y = additional_y.mean(axis=1)\n",
    "\n",
    "            # normalized\n",
    "            temp_df = pd.concat([additional_X, additional_y], axis=1)\n",
    "            ss = StandardScaler()\n",
    "            ss_df = pd.DataFrame(\n",
    "                ss.fit_transform(temp_df), columns=temp_df.columns, index=temp_df.index\n",
    "            )\n",
    "\n",
    "            ss_X = ss_df.iloc[:, :-1]\n",
    "            ss_y = ss_df.iloc[:, -1]\n",
    "\n",
    "            add_X = pd.concat([Y_pre_c, ss_X])\n",
    "            add_y = pd.concat([Y_pre_t, ss_y])\n",
    "\n",
    "            caled_v = estimate_v(additional_X=add_X, additional_y=add_y, Y_pre_t = Y_pre_t, Y_pre_c = Y_pre_c)\n",
    "\n",
    "            return _v_loss(caled_v, X=add_X, y=add_y, Y_pre_t = Y_pre_t, Y_pre_c = Y_pre_c, return_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdid = gen_data(df, PRE_TEREM, POST_TEREM, TREATMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdid = synthdid_estimate(df, PRE_TEREM, POST_TEREM, TREATMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcov(object, method = \"placebo\", replications = 200):\n",
    "    Y_pre_c, Y_pre_t, Y_post_c, Y_post_t = sdid[\"Y_pre_c\"], sdid[\"Y_pre_t\"], sdid[\"Y_post_c\"], sdid[\"Y_post_t\"]\n",
    "    pre_term, post_term = sdid[\"pre_term\"], sdid[\"post_term\"]\n",
    "\n",
    "    if method == \"placebo\":\n",
    "\n",
    "        assert sdid[\"n_treat\"] < Y_pre_c.shape[1]\n",
    "        control_names = Y_pre_c.columns\n",
    "\n",
    "        result_tau_sdid = []\n",
    "\n",
    "        for i in tqdm(range(replications)):\n",
    "            # setup\n",
    "            np.random.seed(seed=0 + i)\n",
    "            placebo_t = np.random.choice(control_names, sdid[\"n_treat\"], replace=False)\n",
    "            placebo_c = [col for col in control_names if col not in placebo_t]\n",
    "            pla_Y_pre_t = Y_pre_c[placebo_t]\n",
    "            pla_Y_post_t = Y_post_c[placebo_t]\n",
    "            pla_Y_pre_c = Y_pre_c[placebo_c]\n",
    "            pla_Y_post_c = Y_post_c[placebo_c]\n",
    "\n",
    "            pla_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"pla_actual_y\": pd.concat([pla_Y_pre_t, pla_Y_post_t]).mean(\n",
    "                        axis=1\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "            post_placebo_treat = pla_result.loc[\n",
    "                post_term[0] :, \"pla_actual_y\"\n",
    "            ].mean()\n",
    "\n",
    "            # estimation\n",
    "            ## sdid\n",
    "            pla_zeta = est_zeta(sdid[\"n_treat\"], sdid[\"n_post_term\"], pla_Y_pre_c)\n",
    "\n",
    "            pla_hat_omega = est_omega(l2_loss, pla_Y_pre_c, pla_Y_pre_t, pla_zeta)\n",
    "            pla_hat_lambda = est_lambda(l2_loss, pla_Y_pre_c, pla_Y_post_c)\n",
    "\n",
    "            # prediction\n",
    "            ## sdid\n",
    "            pla_hat_omega = pla_hat_omega[:-1]\n",
    "            pla_Y_c = pd.concat([pla_Y_pre_c, pla_Y_post_c])\n",
    "            n_features = pla_Y_pre_c.shape[1]\n",
    "            start_w = np.repeat(1 / n_features, n_features)\n",
    "\n",
    "            _intercept = (start_w - pla_hat_omega) @ pla_Y_pre_c.T @ pla_hat_lambda\n",
    "\n",
    "            pla_result[\"sdid\"] = pla_Y_c.dot(pla_hat_omega) + _intercept\n",
    "\n",
    "            # cal tau\n",
    "            ## sdid\n",
    "            pre_sdid = pla_result[\"sdid\"].head(len(pla_hat_lambda)) @ pla_hat_lambda\n",
    "            post_sdid = pla_result.loc[post_term[0] :, \"sdid\"].mean()\n",
    "\n",
    "            pre_treat = (pla_Y_pre_t.T @ pla_hat_lambda).values[0]\n",
    "            sdid_counterfuctual_post_treat = pre_treat + (post_sdid - pre_sdid)\n",
    "\n",
    "            result_tau_sdid.append(\n",
    "                post_placebo_treat - sdid_counterfuctual_post_treat\n",
    "            )\n",
    "    return (np.var(result_tau_sdid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.58459898332936"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(result_tau_sdid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['South Carolina'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(control_names, sdid[\"n_treat\"], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = \"jackknife\"\n",
    "# sdid[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pre_c, Y_pre_t, Y_post_c, Y_post_t = sdid[\"Y_pre_c\"], sdid[\"Y_pre_t\"], sdid[\"Y_post_c\"], sdid[\"Y_post_t\"]\n",
    "pre_term, post_term = sdid[\"pre_term\"], sdid[\"post_term\"]\n",
    "\n",
    "if algo == \"jackknife\":\n",
    "\n",
    "    assert sdid[\"n_treat\"] < Y_pre_c.shape[1]\n",
    "    control_names = Y_pre_c.columns\n",
    "\n",
    "    result_tau_sdid = []\n",
    "    \n",
    "    if (setup$N0 == sdid[\"df\"].shape[0] - 1 or (!is.null(weights) and np.sum(weights$omega != 0) == 1)):\n",
    "        print(\"NA\")\n",
    "\n",
    "    for i in tqdm(range(replications)):\n",
    "            # setup\n",
    "        np.random.seed(seed=0 + i)\n",
    "        placebo_t = np.random.choice(control_names, sdid[\"n_treat\"], replace=False)\n",
    "        placebo_c = [col for col in control_names if col not in placebo_t]\n",
    "        pla_Y_pre_t = Y_pre_c[placebo_t]\n",
    "        pla_Y_post_t = Y_post_c[placebo_t]\n",
    "        pla_Y_pre_c = Y_pre_c[placebo_c]\n",
    "        pla_Y_post_c = Y_post_c[placebo_c]\n",
    "\n",
    "        pla_result = pd.DataFrame(\n",
    "            {\n",
    "                \"pla_actual_y\": pd.concat([pla_Y_pre_t, pla_Y_post_t]).mean(\n",
    "                    axis=1\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        post_placebo_treat = pla_result.loc[\n",
    "            post_term[0] :, \"pla_actual_y\"\n",
    "        ].mean()\n",
    "\n",
    "        # estimation\n",
    "        ## sdid\n",
    "        pla_zeta = est_zeta(sdid[\"n_treat\"], sdid[\"n_post_term\"], pla_Y_pre_c)\n",
    "\n",
    "        pla_hat_omega = est_omega(l2_loss, pla_Y_pre_c, pla_Y_pre_t, pla_zeta)\n",
    "        pla_hat_lambda = est_lambda(l2_loss, pla_Y_pre_c, pla_Y_post_c)\n",
    "        ## sc\n",
    "        # pla_hat_omega_ADH = est_omega_ADH(pla_Y_pre_c, pla_Y_pre_t)\n",
    "\n",
    "        # prediction\n",
    "        ## sdid\n",
    "        pla_hat_omega = pla_hat_omega[:-1]\n",
    "        pla_Y_c = pd.concat([pla_Y_pre_c, pla_Y_post_c])\n",
    "        n_features = pla_Y_pre_c.shape[1]\n",
    "        start_w = np.repeat(1 / n_features, n_features)\n",
    "\n",
    "        _intercept = (start_w - pla_hat_omega) @ pla_Y_pre_c.T @ pla_hat_lambda\n",
    "\n",
    "        pla_result[\"sdid\"] = pla_Y_c.dot(pla_hat_omega) + _intercept\n",
    "\n",
    "        # cal tau\n",
    "        ## sdid\n",
    "        pre_sdid = pla_result[\"sdid\"].head(len(pla_hat_lambda)) @ pla_hat_lambda\n",
    "        post_sdid = pla_result.loc[post_term[0] :, \"sdid\"].mean()\n",
    "\n",
    "        pre_treat = (pla_Y_pre_t.T @ pla_hat_lambda).values[0]\n",
    "        sdid_counterfuctual_post_treat = pre_treat + (post_sdid - pre_sdid)\n",
    "\n",
    "        result_tau_sdid.append(\n",
    "            post_placebo_treat - sdid_counterfuctual_post_treat\n",
    "        )\n",
    "np.var(result_tau_sdid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pla_actual_y</th>\n",
       "      <th>sdid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>108.500000</td>\n",
       "      <td>120.397298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>108.400002</td>\n",
       "      <td>124.281081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>109.400002</td>\n",
       "      <td>129.713514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>110.599998</td>\n",
       "      <td>132.105405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>116.099998</td>\n",
       "      <td>135.170270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>137.375676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>124.400002</td>\n",
       "      <td>141.716216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>125.500000</td>\n",
       "      <td>141.510810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>127.099998</td>\n",
       "      <td>140.835135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>124.199997</td>\n",
       "      <td>138.462163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>124.599998</td>\n",
       "      <td>138.454054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>132.899994</td>\n",
       "      <td>138.124324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>116.199997</td>\n",
       "      <td>136.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>115.599998</td>\n",
       "      <td>131.672974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>111.199997</td>\n",
       "      <td>125.272973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>109.400002</td>\n",
       "      <td>123.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>104.099998</td>\n",
       "      <td>121.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>101.099998</td>\n",
       "      <td>118.032433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>100.199997</td>\n",
       "      <td>114.191891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>94.400002</td>\n",
       "      <td>110.075676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>95.400002</td>\n",
       "      <td>105.943243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>97.099998</td>\n",
       "      <td>104.537837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>95.199997</td>\n",
       "      <td>103.616216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>92.500000</td>\n",
       "      <td>102.970270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>93.400002</td>\n",
       "      <td>102.354054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>103.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>101.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>93.900002</td>\n",
       "      <td>102.002703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>101.145945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>91.699997</td>\n",
       "      <td>97.754054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>88.900002</td>\n",
       "      <td>92.221622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pla_actual_y        sdid\n",
       "1970    108.500000  120.397298\n",
       "1971    108.400002  124.281081\n",
       "1972    109.400002  129.713514\n",
       "1973    110.599998  132.105405\n",
       "1974    116.099998  135.170270\n",
       "1975    120.500000  137.375676\n",
       "1976    124.400002  141.716216\n",
       "1977    125.500000  141.510810\n",
       "1978    127.099998  140.835135\n",
       "1979    124.199997  138.462163\n",
       "1980    124.599998  138.454054\n",
       "1981    132.899994  138.124324\n",
       "1982    116.199997  136.837838\n",
       "1983    115.599998  131.672974\n",
       "1984    111.199997  125.272973\n",
       "1985    109.400002  123.486486\n",
       "1986    104.099998  121.040541\n",
       "1987    101.099998  118.032433\n",
       "1988    100.199997  114.191891\n",
       "1989     94.400002  110.075676\n",
       "1990     95.400002  105.943243\n",
       "1991     97.099998  104.537837\n",
       "1992     95.199997  103.616216\n",
       "1993     92.500000  102.970270\n",
       "1994     93.400002  102.354054\n",
       "1995     93.000000  103.432432\n",
       "1996     94.000000  101.378378\n",
       "1997     93.900002  102.002703\n",
       "1998     94.000000  101.145945\n",
       "1999     91.699997   97.754054\n",
       "2000     88.900002   92.221622"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pla_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placebo_se = function(estimate, replications) {\n",
    "    setup = attr(estimate, 'setup')\n",
    "    opts = attr(estimate, 'opts')\n",
    "    weights = attr(estimate, 'weights')\n",
    "    N1 = nrow(setup$Y) - setup$N0\n",
    "    if (setup$N0 <= N1) { stop('must have more controls than treated units to use the placebo se') }\n",
    "    theta = function(ind) {\n",
    "\tN0 = length(ind)-N1\n",
    "\tweights.boot = weights\n",
    "\tweights.boot$omega = sum_normalize(weights$omega[ind[1:N0]])\n",
    "        do.call(synthdid_estimate, c(list(Y=setup$Y[ind,], N0=N0,  T0=setup$T0,  X=setup$X[ind, ,], weights=weights.boot), opts))\n",
    "    }\n",
    "    sqrt((replications-1)/replications) * sd(replicate(replications, theta(sample(1:setup$N0))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = function(ind) {\n",
    "N0 = length(ind)-N1\n",
    "weights.boot = weights\n",
    "weights.boot$omega = sum_normalize(weights$omega[ind[1:N0]])\n",
    "    do.call(synthdid_estimate, c(list(Y=setup$Y[ind,], N0=N0,  T0=setup$T0,  X=setup$X[ind, ,], weights=weights.boot), opts))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(ind):\n",
    "    N0 = len(ind) - N1\n",
    "    weights_boot = weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd13bc16400e16874b7ce28af58a129343287e94248a182c1f06fbb6b76ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
